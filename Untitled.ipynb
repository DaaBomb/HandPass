{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "protoFile = \"hand/pose_deploy.prototxt\"\n",
    "weightsFile = \"hand/pose_iter_102000.caffemodel\"\n",
    "nPoints = 22\n",
    "POSE_PAIRS = [ [0,1],[1,2],[2,3],[3,4],[0,5],[5,6],[6,7],[7,8],[0,9],[9,10],[10,11],[11,12],[0,13],[13,14],[14,15],[15,16],[0,17],[17,18],[18,19],[19,20] ]\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "input_source = \"asl.mp4\"\n",
    "cap = cv2.VideoCapture(input_source)\n",
    "hasFrame, frame = cap.read()\n",
    "\n",
    "frameWidth = frame.shape[1]\n",
    "frameHeight = frame.shape[0]\n",
    "\n",
    "aspect_ratio = frameWidth/frameHeight\n",
    "\n",
    "inHeight = 368\n",
    "inWidth = int(((aspect_ratio*inHeight)*8)//8)\n",
    "\n",
    "vid_writer = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "k = 0\n",
    "\n",
    "smoothed_data, data, previous_points, frame_number = [], [], [], 0\n",
    "for i in range(nPoints): previous_points.append((0,0))\n",
    "# Smoothing parameters - choose a window length of about 1/2 to 1/4 the fps (so 60 fps --> window length of 33)\n",
    "window_length, exponent_value = 33,2 # Window length must be odd\n",
    "\n",
    "### This is going to take some time before the party get's started! The downside of smoothing is that\n",
    "### data from the past and the future is required to smooth data in the present. This means that all the frames\n",
    "### in the video must be processed before smoothing the data and displaying the result. This method is therefore\n",
    "### not suitable for realtime results.\n",
    "while 1:\n",
    "    k+=1\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    frameCopy = np.copy(frame)\n",
    "    if not hasFrame:\n",
    "        break\n",
    "\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                              (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    output = net.forward()\n",
    "\n",
    "    print(\"forward = {}\".format(time.time() - t))\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "\n",
    "    for i in range(nPoints):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "        probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        if prob > threshold :\n",
    "            cv2.circle(frameCopy, (int(point[0]), int(point[1])), 6, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(point[0]), int(point[1])), cv2.FONT_HERSHEY_SIMPLEX, .8, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(point[0]), int(point[1])))\n",
    "        else :\n",
    "            # Add the last known point (ex: if thumb is not detected, use thumb position from previous frame)\n",
    "            points.append(previous_points[i])\n",
    "\n",
    "    # Save the data from the model - data is a list of lists. Each element is a list containing the 22 coordinates for the hand.\n",
    "    data.append(points)\n",
    "    \n",
    "    previous_points = points\n",
    "\n",
    "    print(\"total = {}\".format(time.time() - t))\n",
    "\n",
    "# Re-capture the source, so that the video starts at the beginning again\n",
    "cap = cv2.VideoCapture(input_source)\n",
    "\n",
    "# Smooth it out\n",
    "# Split the data so that just the x values for the first point are made into a list\n",
    "smoothed_data_in_series = []\n",
    "for point_index in range(nPoints): # Iterate through each point (wrist, thumb, etc...)\n",
    "    data_point_series_x = []\n",
    "    data_point_series_y = []\n",
    "    for values in data: # Iterate through the series of data (each frame of video)\n",
    "        data_point_series_x.append(values[point_index][0])\n",
    "        data_point_series_y.append(values[point_index][1])\n",
    "    # Smooth the x and y values\n",
    "    smoothed_data_point_series_x = signal.savgol_filter(data_point_series_x, window_length, exponent_value)\n",
    "    smoothed_data_point_series_y = signal.savgol_filter(data_point_series_y, window_length, exponent_value)\n",
    "    smoothed_data_in_series.append(smoothed_data_point_series_x)\n",
    "    smoothed_data_in_series.append(smoothed_data_point_series_y)\n",
    "    \n",
    "# Now the data is sepearted into 44 lists (two lists for each of the 22 locations of the hand, time to zip()\n",
    "for current_frame_number in range(len(smoothed_data_in_series[0])):\n",
    "    frame_values = []\n",
    "    for point_index in range(nPoints):\n",
    "        x = smoothed_data_in_series[point_index*2][current_frame_number]\n",
    "        y = smoothed_data_in_series[point_index*2+1][current_frame_number]\n",
    "        frame_values.append((x,y))\n",
    "    smoothed_data.append(frame_values)\n",
    "\n",
    "# Iterate through each frame of data\n",
    "for values in smoothed_data:\n",
    "    \n",
    "    hasFrame, img = cap.read()\n",
    "\n",
    "    # When data is smoothed, floats are introduced, these must be eliminated becase cv2.circle requries integers\n",
    "    values = np.array(values, int)  \n",
    "    \n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "        cv2.line(img, (values[partA][0], values[partA][1]),(values[partB][0], values[partB][1]), (32, 255, 0), 2, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(img, (values[partA][0], values[partA][1]), 2, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.circle(img, (values[partB][0], values[partB][1]), 2, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "    cv2.imshow('Output-Skeleton', img)\n",
    "    cv2.waitKey(0)\n",
    "    vid_writer.write(img)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "vid_writer.release()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
